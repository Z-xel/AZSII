# Практика 8: Методы защиты от атак на модели ИИ


Выполнил студент группы ББМО-01-23 Курдюков А.А.

Ссылка на notebook в Google colab: https://colab.research.google.com/drive/14sydJLBptDhwYyWA86lgNLA8JuRKD2d_?usp=sharing

## Цель задания:

Изучить методы защиты моделей ИИ от различных атак, включая методы защиты на уровне данных,
моделирования и обучения. Реализовать эти методы и проверить их эффективность против атак,
изученных ранее.

Задачи:

1. Изучить и реализовать защиту модели с помощью тренировок на противоречивых примерах (Adversarial Training).
2. Реализовать метод защиты на основе градиентной маскировки.
3. Использовать регуляризацию и нормализацию для повышения устойчивости модели.
4. Проверить эффективность методов защиты против атак FGSM, PGD и GAN-based атак.
5. Оценить улучшение точности защищенной модели на противоречивых примерах.






